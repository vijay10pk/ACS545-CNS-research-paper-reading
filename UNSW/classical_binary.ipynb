{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error, roc_curve, classification_report,auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('traindata.csv', index_col = 0)\n",
    "testdata = pd.read_csv('testdata.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>90909.0902</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.0003</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0051</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>166666.6608</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2126</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0025</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur  proto  service  state  spkts  dpkts  sbytes  dbytes         rate   \n",
       "0  0.000011    117        0      4      2      0     496       0   90909.0902  \\\n",
       "1  0.000008    117        0      4      2      0    1762       0  125000.0003   \n",
       "2  0.000005    117        0      4      2      0    1068       0  200000.0051   \n",
       "3  0.000006    117        0      4      2      0     900       0  166666.6608   \n",
       "4  0.000010    117        0      4      2      0    2126       0  100000.0025   \n",
       "\n",
       "   sttl  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd   \n",
       "0   254  ...                 1               2             0           0  \\\n",
       "1   254  ...                 1               2             0           0   \n",
       "2   254  ...                 1               3             0           0   \n",
       "3   254  ...                 1               3             0           0   \n",
       "4   254  ...                 1               3             0           0   \n",
       "\n",
       "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat   \n",
       "0                 0           1           2                0           6  \\\n",
       "1                 0           1           2                0           6   \n",
       "2                 0           1           3                0           6   \n",
       "3                 0           2           3                0           6   \n",
       "4                 0           2           3                0           6   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train = traindata.select_dtypes(exclude=[np.number])\n",
    "print(train.columns)\n",
    "for feature in train.columns:\n",
    "    traindata[feature] = LabelEncoder().fit_transform(traindata[feature])\n",
    "\n",
    "test = testdata.select_dtypes(exclude=[np.number])\n",
    "print(test.columns)\n",
    "for feature in test.columns:\n",
    "    testdata[feature] = LabelEncoder().fit_transform(testdata[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainD = traindata.groupby('label', group_keys=False).apply(lambda x: x.sample(frac=0.05))\n",
    "testD = testdata.groupby('label', group_keys=False).apply(lambda x: x.sample(frac=0.07))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainD.iloc[:,0:43]\n",
    "Y = trainD.iloc[:,43]\n",
    "C = testD.iloc[:,43]\n",
    "T = testD.iloc[:,0:43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "\n",
    "traindata = np.array(trainX)\n",
    "trainlabel = np.array(Y)\n",
    "\n",
    "testdata = np.array(testT)\n",
    "testlabel = np.array(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(traindata, trainlabel)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941\n",
      "0.651\n",
      "Accuracy\n",
      "0.7433599478572592\n",
      "precision\n",
      "0.9590684544812985\n",
      "recall\n",
      "0.6507062485037108\n",
      "f-score\n",
      "0.7753530166880617\n",
      "fpr\n",
      "0.651\n",
      "tpr\n",
      "0.941\n"
     ]
    }
   ],
   "source": [
    "# summarize the fit of the model\n",
    "\n",
    "cm = confusion_matrix(expected, predicted)\n",
    "# print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(expected, predicted))\n",
    "print(\"precision\")\n",
    "print(precision_score(expected, predicted ,average='binary'))\n",
    "print(\"recall\")\n",
    "print(recall_score(expected, predicted ,average='binary'))\n",
    "print(\"f-score\")\n",
    "print(f1_score(expected, predicted , average='binary'))\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    }
   ],
   "source": [
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "model.fit(traindata, trainlabel)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.266\n",
      "0.996\n",
      "Accuracy\n",
      "0.7626690565422845\n",
      "precision\n",
      "0.7430536942732064\n",
      "recall\n",
      "0.9955709839597797\n",
      "f-score\n",
      "0.8509745741034429\n",
      "fpr\n",
      "0.996\n",
      "tpr\n",
      "0.266\n"
     ]
    }
   ],
   "source": [
    "# summarize the fit of the model\n",
    "\n",
    "cm = confusion_matrix(expected, predicted)\n",
    "# print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(expected, predicted))\n",
    "print(\"precision\")\n",
    "print(precision_score(expected, predicted ,average='binary'))\n",
    "print(\"recall\")\n",
    "print(recall_score(expected, predicted ,average='binary'))\n",
    "print(\"f-score\")\n",
    "print(f1_score(expected, predicted , average='binary'))\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n"
     ]
    }
   ],
   "source": [
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(traindata, trainlabel)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.838\n",
      "0.756\n",
      "Accuracy\n",
      "0.7822225843245886\n",
      "precision\n",
      "0.908411214953271\n",
      "recall\n",
      "0.7562844146516638\n",
      "f-score\n",
      "0.8253968253968254\n",
      "fpr\n",
      "0.756\n",
      "tpr\n",
      "0.838\n"
     ]
    }
   ],
   "source": [
    "# summarize the fit of the model\n",
    "\n",
    "cm = confusion_matrix(expected, predicted)\n",
    "# print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(expected, predicted))\n",
    "print(\"precision\")\n",
    "print(precision_score(expected, predicted ,average='binary'))\n",
    "print(\"recall\")\n",
    "print(recall_score(expected, predicted ,average='binary'))\n",
    "print(\"f-score\")\n",
    "print(f1_score(expected, predicted , average='binary'))\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(traindata, trainlabel)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876\n",
      "0.804\n",
      "Accuracy\n",
      "0.8271956982238879\n",
      "precision\n",
      "0.932426807270709\n",
      "recall\n",
      "0.8044050754129758\n",
      "f-score\n",
      "0.863697705802969\n",
      "fpr\n",
      "0.804\n",
      "tpr\n",
      "0.876\n"
     ]
    }
   ],
   "source": [
    "# summarize the fit of the model\n",
    "\n",
    "cm = confusion_matrix(expected, predicted)\n",
    "# print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(expected, predicted))\n",
    "print(\"precision\")\n",
    "print(precision_score(expected, predicted ,average='binary'))\n",
    "print(\"recall\")\n",
    "print(recall_score(expected, predicted ,average='binary'))\n",
    "print(\"f-score\")\n",
    "print(f1_score(expected, predicted , average='binary'))\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "model.fit(traindata, trainlabel)\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965\n",
      "0.658\n",
      "Accuracy\n",
      "0.7559882678833306\n",
      "precision\n",
      "0.9755102040816327\n",
      "recall\n",
      "0.6580081398132631\n",
      "f-score\n",
      "0.7859032096647366\n",
      "fpr\n",
      "0.658\n",
      "tpr\n",
      "0.965\n"
     ]
    }
   ],
   "source": [
    "# summarize the fit of the model\n",
    "\n",
    "cm = confusion_matrix(expected, predicted)\n",
    "# print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(expected, predicted))\n",
    "print(\"precision\")\n",
    "print(precision_score(expected, predicted ,average='binary'))\n",
    "print(\"recall\")\n",
    "print(recall_score(expected, predicted ,average='binary'))\n",
    "print(\"f-score\")\n",
    "print(f1_score(expected, predicted , average='binary'))\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model = model.fit(traindata, trainlabel)\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953\n",
      "0.737\n",
      "Accuracy\n",
      "0.8058497637282059\n",
      "precision\n",
      "0.9709733396434769\n",
      "recall\n",
      "0.7367728034474503\n",
      "f-score\n",
      "0.8378139249982984\n",
      "fpr\n",
      "0.737\n",
      "tpr\n",
      "0.953\n"
     ]
    }
   ],
   "source": [
    "# summarize the fit of the model\n",
    "\n",
    "cm = confusion_matrix(expected, predicted)\n",
    "# print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(expected, predicted))\n",
    "print(\"precision\")\n",
    "print(precision_score(expected, predicted ,average='binary'))\n",
    "print(\"recall\")\n",
    "print(recall_score(expected, predicted ,average='binary'))\n",
    "print(\"f-score\")\n",
    "print(f1_score(expected, predicted , average='binary'))\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "X_train = traindata\n",
    "y_train = trainlabel\n",
    "X_test = testdata\n",
    "y_test = testlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vijay/Desktop/MS/Crypto And Network Security/Research Paper Implementation/Network-Intrusion-Detection-master/crypto_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vijay/Desktop/MS/Crypto And Network Security/Research Paper Implementation/Network-Intrusion-Detection-master/crypto_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vijay/Desktop/MS/Crypto And Network Security/Research Paper Implementation/Network-Intrusion-Detection-master/crypto_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vijay/Desktop/MS/Crypto And Network Security/Research Paper Implementation/Network-Intrusion-Detection-master/crypto_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vijay/Desktop/MS/Crypto And Network Security/Research Paper Implementation/Network-Intrusion-Detection-master/crypto_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.705 (+/-0.021) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.275 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.767 (+/-0.011) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.705 (+/-0.021) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.769 (+/-0.014) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.767 (+/-0.011) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.770 (+/-0.013) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.769 (+/-0.014) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.769 (+/-0.012) for {'C': 1, 'kernel': 'linear'}\n",
      "0.771 (+/-0.012) for {'C': 10, 'kernel': 'linear'}\n",
      "0.770 (+/-0.012) for {'C': 100, 'kernel': 'linear'}\n",
      "0.771 (+/-0.011) for {'C': 1000, 'kernel': 'linear'}\n",
      "----------------------------------------------\n",
      "cross-validation accuracy of train data set\n",
      "[0.70532467 0.27532176 0.76681339 0.70532467 0.76913729 0.76681339\n",
      " 0.76981835 0.76913729 0.76931265 0.77050024 0.77038291 0.77137382]\n",
      "----------------------------------------------\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "confusion matrix\n",
      "[[3706  214]\n",
      " [2866 5488]]\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.71      3920\n",
      "           1       0.96      0.66      0.78      8354\n",
      "\n",
      "    accuracy                           0.75     12274\n",
      "   macro avg       0.76      0.80      0.74     12274\n",
      "weighted avg       0.84      0.75      0.76     12274\n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "for now\n",
      "accuracy score\n",
      "0.7490630601270979\n",
      "precision\n",
      "0.9624693090143809\n",
      "recall\n",
      "0.6569308115872636\n",
      "F-score\n",
      "0.7808764940239045\n",
      "best parameters\n",
      "{'C': 1000, 'kernel': 'linear'}\n",
      "***************************************************************************\n",
      "==============================================\n",
      "[[3706  214]\n",
      " [2866 5488]]\n",
      "0.945\n",
      "0.657\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.707 (+/-0.020) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.761 (+/-0.009) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.707 (+/-0.020) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.012) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.761 (+/-0.009) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.765 (+/-0.012) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.012) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.765 (+/-0.011) for {'C': 1, 'kernel': 'linear'}\n",
      "0.766 (+/-0.011) for {'C': 10, 'kernel': 'linear'}\n",
      "0.766 (+/-0.011) for {'C': 100, 'kernel': 'linear'}\n",
      "0.767 (+/-0.010) for {'C': 1000, 'kernel': 'linear'}\n",
      "----------------------------------------------\n",
      "cross-validation accuracy of train data set\n",
      "[0.70661152 0.5        0.76099955 0.70661152 0.76432765 0.76099955\n",
      " 0.76503845 0.76432765 0.76454791 0.76574973 0.76569972 0.76668177]\n",
      "----------------------------------------------\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "confusion matrix\n",
      "[[3706  214]\n",
      " [2866 5488]]\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.71      3920\n",
      "           1       0.96      0.66      0.78      8354\n",
      "\n",
      "    accuracy                           0.75     12274\n",
      "   macro avg       0.76      0.80      0.74     12274\n",
      "weighted avg       0.84      0.75      0.76     12274\n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "for now\n",
      "accuracy score\n",
      "0.7490630601270979\n",
      "precision\n",
      "0.9624693090143809\n",
      "recall\n",
      "0.6569308115872636\n",
      "F-score\n",
      "0.7808764940239045\n",
      "best parameters\n",
      "{'C': 1000, 'kernel': 'linear'}\n",
      "***************************************************************************\n",
      "==============================================\n",
      "[[3706  214]\n",
      " [2866 5488]]\n",
      "0.945\n",
      "0.657\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"cross-validation accuracy of train data set\")\n",
    "    print(means)\n",
    "    \n",
    "    print(\"----------------------------------------------\")\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    #print(\"accuracy score\")\n",
    "    #print(accuracy_score(y_true, y_pred))\n",
    "    print(\"confusion matrix\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"***************************************************************************\")\n",
    "    print(\"for now\")\n",
    "    print(\"accuracy score\")\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "    print(\"precision\")\n",
    "    print(precision_score(y_true, y_pred , average=\"binary\"))\n",
    "    print(\"recall\")\n",
    "    print(recall_score(y_true, y_pred , average=\"binary\"))\n",
    "    print(\"F-score\")\n",
    "    print(f1_score(y_true, y_pred , average=\"binary\"))\n",
    "    print(\"best parameters\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"***************************************************************************\")\n",
    "    predicted = y_pred\n",
    "    expected = y_true\n",
    "    cm = metrics.confusion_matrix(expected, predicted)\n",
    "    print(\"==============================================\")\n",
    "    print(cm)\n",
    "    tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "    fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "    print(\"%.3f\" %tpr)\n",
    "    print(\"%.3f\" %fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
