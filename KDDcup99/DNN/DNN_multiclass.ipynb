{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d308afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('../dataset/traindata.csv', index_col = 0)\n",
    "testdata = pd.read_csv('../dataset/traindata.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce273c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c379b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = traindata.select_dtypes(exclude=[np.number])\n",
    "print(train.columns)\n",
    "for feature in train.columns:\n",
    "    traindata[feature] = LabelEncoder().fit_transform(traindata[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = testdata.select_dtypes(exclude=[np.number])\n",
    "print(test.columns)\n",
    "for feature in test.columns:\n",
    "    testdata[feature] = LabelEncoder().fit_transform(testdata[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01bae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainD = traindata.groupby('target', group_keys=False).apply(lambda x: x.sample(frac=0.05))\n",
    "testD = testdata.groupby('target', group_keys=False).apply(lambda x: x.sample(frac=0.07))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e222af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainD.iloc[:,0:41]\n",
    "Y = trainD.iloc[:,41]\n",
    "C = testD.iloc[:,41]\n",
    "T = testD.iloc[:,0:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d621dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.array(X)\n",
    "testT = np.array(T)\n",
    "\n",
    "trainX.astype(float)\n",
    "testT.astype(float)\n",
    "\n",
    "scaler = Normalizer().fit(trainX)\n",
    "trainX = scaler.transform(trainX)\n",
    "\n",
    "scaler = Normalizer().fit(testT)\n",
    "testT = scaler.transform(testT)\n",
    "\n",
    "y_train1 = np.array(Y)\n",
    "y_test1 = np.array(C)\n",
    "\n",
    "y_train= to_categorical(y_train1)\n",
    "y_test= to_categorical(y_test1)\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e980b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1 Layer DNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94138e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=41,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(23))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/dnn1layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('kddresults/dnn1layer/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, epochs=100, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"kddresults/dnn1layer/dnn1layer_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2 Layer DNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21381e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=41,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(23))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/dnn2layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('kddresults/dnn2layer/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, epochs=100, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"kddresults/dnn2layer/dnn2layer_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"3 Layer DNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da5a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=41,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(23))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/dnn3layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('kddresults/dnn3layer/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=100, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"kddresults/dnn3layer/dnn3layer_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"4 Layer DNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a79026",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=41,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(256,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(23))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/dnn4layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('kddresults/dnn4layer/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, epochs=100, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"kddresults/dnn4layer/dnn4layer_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2238482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"5 Layer DNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=41,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(256,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(128,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(23))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/dnn5layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('kddresults/dnn5layer/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, epochs=100, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"kddresults/dnn5layer/dnn5layer_model.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
